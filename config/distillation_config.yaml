basic:
  # set random seed 
  seed: 42
  # set mixed precision
  use_amp: true
  # enable/disable fp16
  fp16: false
  # set gpu 
  cuda_device_id: 0
  # set the number of training steps to print the logger
  logging_steps: 100
  # set dropout layer value
  drop_p: !!float "0.1"

data:
  # set data set path including training set and test set
  train_data_path: train.jsonl
  test_data_path: test.jsonl
  # set the batch size of train dataset and test dataset
  train_batch_size: 128
  test_batch_size: 128
  # set the maximum length of each data
  max_seq_len: 64
  # number of labels
  num_classes: 4

model: 
  # model name or absolute path
  model_name: "distilbert-base-uncased"
  initial_model_path: null

distill: 
  # load distilled data
  distilled_load_path: null
  # save distilled data
  distilled_save_path: distilled_data.pt
  # number of distillations each class
  data_size: 2
  accum_loss: false
  # random init model parameters
  random_init: false
  # set epoch
  n_distill_epochs: 10
  # optimizer parameter
  optimize_lr: false
  distill_lr: !!float "2e-3"
  distill_warmup_ratio: !!float "0.1"
  distill_model_lr: !!float "0.5"
  distill_step_lr_gamma: !!float "0.2"
  distill_max_grad_norm: !!float "1.0"
  # steps to update model parameters
  n_inner_steps: 3